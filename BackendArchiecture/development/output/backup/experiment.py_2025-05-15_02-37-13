import numpy as np
import pandas as pd
from sklearn.model_selection import KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

# Generate a synthetic dataset (replace with your actual data loading)
np.random.seed(42)
X = np.random.rand(1000, 10)  # 1000 samples, 10 features
y = np.random.rand(1000)  # 1000 target values

# Convert to Pandas DataFrame for easier handling
X = pd.DataFrame(X)
y = pd.Series(y)


# Function to remove outliers using the IQR method
def remove_outliers_iqr(X, y, threshold=1.5):
    """Removes outliers from the target variable using the IQR method.

    Args:
        X (pd.DataFrame): The feature matrix.
        y (pd.Series): The target variable.
        threshold (float): The IQR threshold for outlier detection.

    Returns:
        pd.DataFrame: The feature matrix without outliers.
        pd.Series: The target variable without outliers.
    """
    Q1 = y.quantile(0.25)
    Q3 = y.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - threshold * IQR
    upper_bound = Q3 + threshold * IQR
    
    # Identify outliers
    outlier_indices = y[(y < lower_bound) | (y > upper_bound)].index
    
    # Remove outliers from both X and y
    X_filtered = X.drop(outlier_indices)
    y_filtered = y.drop(outlier_indices)
    
    return X_filtered, y_filtered


# Apply outlier removal
X_filtered, y_filtered = remove_outliers_iqr(X, y)


# Data scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_filtered)
X_scaled = pd.DataFrame(X_scaled, index=X_filtered.index, columns=X_filtered.columns)  # Preserve index


# Define the model
model = RandomForestRegressor(n_estimators=100, random_state=42)  # Example hyperparameters

# K-Fold Cross-Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)
rmse_scores = []

for train_index, test_index in kf.split(X_scaled):
    X_train, X_test = X_scaled.iloc[train_index], X_scaled.iloc[test_index]
    y_train, y_test = y_filtered.iloc[train_index], y_filtered.iloc[test_index]
    
    # Train the model
    model.fit(X_train, y_train)
    
    # Make predictions
    y_pred = model.predict(X_test)
    
    # Evaluate the model
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    rmse_scores.append(rmse)

# Print the results
print("RMSE scores for each fold:", rmse_scores)
print("Mean RMSE:", np.mean(rmse_scores))